---
title: "Homework 6"
author: "[Insert your name here]{style='background-color: yellow;'}"
toc: true
title-block-banner: true
title-block-style: default
execute: 
  freeze: true
  cache: true
# format:
  html: # comment this line to get pdf
  pdf: 
    fig-width: 7
    fig-height: 7
---


::: {.callout-important style="font-size: 0.8em;"}

Please read the instructions carefully before submitting your assignment.

1. This assignment requires you to only upload a `PDF` file on Canvas
1. Don't collapse any code cells before submitting. 
1. Remember to make sure all your code output is rendered properly before uploading your submission.

⚠️ Please add your name to the author information in the frontmatter before submitting your assignment ⚠️
:::


In this assignment, we will perform various tasks involving principal component analysis (PCA), principal component regression, and dimensionality reduction.

We will need the following packages:


```{R, message=FALSE, warning=FALSE, results='hide'}
packages <- c(
  "tibble",
  "dplyr", 
  "readr", 
  "tidyr", 
  "purrr", 
  "broom",
  "magrittr",
  "corrplot",
  "car"
)
# renv::install(packages)
sapply(packages, require, character.only=T)
```

<br><br><br><br>
---

## Question 1
::: {.callout-tip}
## 70 points
Principal component anlaysis and variable selection
:::

###### 1.1 (5 points)


The `data` folder contains a `spending.csv` dataset which is an illustrative sample of monthly spending data for a group of $5000$ people across a variety of categories. The response variable, `income`, is their monthly income, and objective is to predict the `income` for a an individual based on their spending patterns.

Read the data file as a tibble in R. Preprocess the data such that:

1. the variables are of the right data type, e.g., categorical variables are encoded as factors
2. all column names to lower case for consistency
3. Any observations with missing values are dropped

```{R}
path <- "data/spending.csv"

df <- read_csv(path)
```
```{R}

df <- df %>% as_tibble() %>% drop_na()



```

---

###### 1.2 (5 points)

Visualize the correlation between the variables using the `corrplot()` function. What do you observe? What does this mean for the model?

```{R}
# df_x  %>% ... # Insert your code here

corrplot(cor(df))
```
I observe that most of the variables have some degree of positive correlation with each other.  This means that the model generally favors a positive correlation between variables.
---

###### 1.3 (5 points)

Run a linear regression model to predict the `income` variable using the remaining predictors. Interpret the coefficients and summarize your results. 


```{R}
linreg <- lm(income ~ ., data = df)

summary(linreg)
```
As spending on video games increases by 1, the income of the individual goes up by 0.86.  As spending on vegetables increases by 1, the income of the individual goes down by -0.06.  From this model, it can be observed that only a few variables are predicted to negatively correlate with income, namely vegetables, food_delivery, and alcohol.
---

###### 1.3 (5 points)

Diagnose the model using the `vif()` function. What do you observe? What does this mean for the model?

```{R}

vif(linreg)


```
I observe that some variables have significantly larger values such as restaurant_meals, smartphones, video games, and electronics.  This suggest that there may he a high degree of multicollinearity present in the model.
---

###### 1.4 (5 points)

Perform PCA using the `princomp` function in R. Print the summary of the PCA object.

```{R}
pca <- princomp(df, cor=TRUE)


summary(pca)


```

---

###### 1.5 (5 points)

Make a screeplot of the proportion of variance explained by each principal component. How many principal components would you choose to keep? Why?

```{R}

screeplot(pca)



```
I would choose to keep around four principal components because they are the only components that show significant variances.

###### 1.6 (5 points)

By setting any factor loadings below $0.2$ to $0$, summarize the factor loadings for the principal components that you chose to keep. 

```{R}
clean_loadings <- ifelse(pca$loadings[, 1:4] < 0.2, 0, round(pca$loadings[, 1:4], 2)) %>% as.data.frame()

```

All of the loadings except for ones pertaining to groceries for component 1 are under 0.2, meaning that these items have a weak influence on the factor.  However, all grocery related items have a factor loading of 0.26, which shows a low to moderate influence.

All of the loadings except for ones pertaining to entertainment and lifestyle for component 2 are under 0.2, meaning that these items have a weak influence on the factor.  However, all entertainment and lifestyle related items(ie. gym memberships or movies) share a factor loading of 0.28, suggesting a moderate influence on the factor.

All of the loadings except for ones pertaining to electronics for component 3 are under 0.2, meaning that these items have a weak influence on the factor.  However, all electronic related items share a factor loading of 0.31, signifying a moderate influence on the factor.

All of the loadings except for ones pertaining to accessories and clothing for component 4 are under 0.2, meaning that these items have a weak influence on the factor.  However, all accessory and clothinf related items share a factor loading of 0.45, signifying a strong influence on the factor.


Visualize the factor loadings. 

```{R}

clean_loadings %>% as.matrix() %>% t() %>% corrplot()

```

---

###### 1.7 (15 points)

Based on the factor loadings, what do you think the principal components represent? 

Provide an interpreation for each principal component you chose to keep.

---

###### 1.8 (10 points)

Create a new data frame with the original response variable `income` and the principal components you chose to keep. Call this data frame `df_pca`.

```{R}

Z <- predict(pca, df) 
df_pca <- Z %>% as_tibble %>% select(Comp.1, Comp.2, Comp.3, Comp.4) %>% mutate(income = df$income)
df_pca

```

Fit a regression model to predict the `income` variable using the principal components you chose to keep. Interpret the coefficients and summarize your results. 

```{R}
mod <- lm(income ~ ., data = df_pca)
summary(mod)
     
```
Every time the first principal component increases by 1, the income increases by roughly 17.32.  Every time the second principal component increases by 1, the income decreases by roughly 1.68.
Every time the third principal component increases by 1, the income increases by roughly 90.03.  Every time the fourth principal component increases by 1, the income increases by 7.656.



Compare the results of the regression model in 1.3 and 1.9. What do you observe? What does this mean for the model?

```{R}

summary(linreg)$sigma
summary(mod)$sigma


```
I obeserve that the principal component analysis generally captures the data more accurately with less error in the predictive model.  It also is faster because it only utilizes the principal components(four variables).  This means that the principal components are really what matter the most when predicting data.



---

###### 1.10 (10 points)

Based on your interpretation of the principal components from Question 1.7, provide an interpretation of the regression model in Question 1.9.




---


:::{.hidden unless-format="pdf"}
\pagebreak
:::

<br><br><br><br>
<br><br><br><br>
---



::: {.callout-note collapse="true"}
## Session Information

Print your `R` session information using the following command

```{R}
sessionInfo()
```
:::